From: Stefan Behrens <sbehrens@giantdisaster.de>
Date: Tue, 27 Mar 2012 14:21:27 -0400
Patch-mainline: 3.4
Subject: [PATCH] Btrfs: change scrub to support big blocks

Scrub used to be coded for nodesize == leafsize == sectorsize == PAGE_SIZE.
This is now changed to support sizes for nodesize and leafsize which are
N * PAGE_SIZE.

Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>
Signed-off-by: Chris Mason <chris.mason@oracle.com>
Signed-off-by: David Sterba <dsterba@suse.cz>

Automatically created from "patches.suse/btrfs-0480-change-scrub-to-support-big-blocks.patch" by xen-port-patches.py

--- sle11sp3.orig/arch/x86/include/mach-xen/asm/hypervisor.h	2011-08-23 15:26:08.000000000 +0200
+++ sle11sp3/arch/x86/include/mach-xen/asm/hypervisor.h	2012-05-11 16:45:57.000000000 +0200
@@ -132,9 +132,9 @@ bool __cold hypervisor_oom(void);
 u64 jiffies_to_st(unsigned long jiffies);
 
 #ifdef CONFIG_XEN_SCRUB_PAGES
-void scrub_pages(void *, unsigned int);
+void xen_scrub_pages(void *, unsigned int);
 #else
-#define scrub_pages(_p,_n) ((void)0)
+#define xen_scrub_pages(_p,_n) ((void)0)
 #endif
 
 #if defined(CONFIG_XEN) && !defined(MODULE)
--- sle11sp3.orig/arch/x86/lib/scrub.c	2008-02-08 12:30:51.000000000 +0100
+++ sle11sp3/arch/x86/lib/scrub.c	2012-04-13 14:47:07.000000000 +0200
@@ -2,7 +2,7 @@
 #include <asm/page.h>
 #include <asm/processor.h>
 
-void scrub_pages(void *v, unsigned int count)
+void xen_scrub_pages(void *v, unsigned int count)
 {
 	if (likely(cpu_has_xmm2)) {
 		unsigned long n = count * (PAGE_SIZE / sizeof(long) / 4);
--- sle11sp3.orig/arch/x86/mm/hypervisor.c	2011-08-09 14:31:55.000000000 +0200
+++ sle11sp3/arch/x86/mm/hypervisor.c	2012-05-31 14:45:36.000000000 +0200
@@ -612,7 +612,7 @@ int xen_create_contiguous_region(
 
 	set_xen_guest_handle(exchange.out.extent_start, &out_frame);
 
-	scrub_pages((void *)vstart, 1 << order);
+	xen_scrub_pages((void *)vstart, 1 << order);
 
 	balloon_lock(flags);
 
@@ -720,7 +720,7 @@ void xen_destroy_contiguous_region(unsig
 
 	set_xen_guest_handle(exchange.in.extent_start, &in_frame);
 
-	scrub_pages((void *)vstart, 1 << order);
+	xen_scrub_pages((void *)vstart, 1 << order);
 
 	balloon_lock(flags);
 
@@ -911,10 +911,10 @@ int xen_limit_pages_to_max_mfn(
 		}
 
 		if (!PageHighMem(page))
-			scrub_pages(page_address(page), 1);
+			xen_scrub_pages(page_address(page), 1);
 #ifdef CONFIG_XEN_SCRUB_PAGES
 		else {
-			scrub_pages(kmap(page), 1);
+			xen_scrub_pages(kmap(page), 1);
 			kunmap(page);
 			++n;
 		}
--- sle11sp3.orig/drivers/xen/balloon/balloon.c	2012-10-19 08:43:51.000000000 +0200
+++ sle11sp3/drivers/xen/balloon/balloon.c	2012-06-08 10:38:39.000000000 +0200
@@ -371,7 +371,7 @@ static int decrease_reservation(unsigned
 
 		if (!PageHighMem(page)) {
 			v = phys_to_virt(pfn << PAGE_SHIFT);
-			scrub_pages(v, 1);
+			xen_scrub_pages(v, 1);
 #ifdef CONFIG_XEN
 			ret = HYPERVISOR_update_va_mapping(
 				(unsigned long)v, __pte_ma(0), 0);
@@ -381,7 +381,7 @@ static int decrease_reservation(unsigned
 #ifdef CONFIG_XEN_SCRUB_PAGES
 		else {
 			v = kmap(page);
-			scrub_pages(v, 1);
+			xen_scrub_pages(v, 1);
 			kunmap(page);
 		}
 #endif
@@ -697,7 +697,7 @@ struct page **alloc_empty_pages_and_page
 			goto err;
 
 		v = page_address(page);
-		scrub_pages(v, 1);
+		xen_scrub_pages(v, 1);
 
 		balloon_lock(flags);
 
