From: Jiri Kosina <jkosina@suse.cz>
Subject: [PATCH] kaiser: work around kABI
References: bsc#1068032 CVE-2017-5754
Patch-mainline: Never, SUSE-specific

The most potentially dangerous one is the vmstats one.  I can't imagine what
3rd party module would realistically be directly allocating pglist_data,
per_cpu_nodestat, memcg_stat_item, lruvec_stat, etc, but the potential
non-zero risk is there.

Signed-off-by: Jiri Kosina <jkosina@suse.cz>

---
 arch/x86/include/asm/desc.h          |    4 ++++
 arch/x86/include/asm/fixmap.h        |    2 ++
 arch/x86/include/asm/hw_irq.h        |    4 ++++
 arch/x86/include/asm/pgtable_types.h |    4 ++++
 arch/x86/include/asm/processor.h     |    4 ++++
 arch/x86/include/asm/tlbflush.h      |    2 ++
 arch/x86/kernel/cpu/common.c         |    4 ++++
 arch/x86/kernel/init_task.c          |    4 ++++
 include/linux/mmu_context.h          |    2 ++
 include/linux/mmzone.h               |    4 +++-
 kernel/sched.c                       |    4 ++++
 mm/vmstat.c                          |    4 +++-
 12 files changed, 40 insertions(+), 2 deletions(-)

--- a/arch/x86/include/asm/desc.h
+++ b/arch/x86/include/asm/desc.h
@@ -40,7 +40,11 @@ struct gdt_page {
 	struct desc_struct gdt[GDT_ENTRIES];
 } __attribute__((aligned(PAGE_SIZE)));
 
+#ifdef __GENKSYMS__
+DECLARE_PER_CPU_PAGE_ALIGNED(struct gdt_page, gdt_page);
+#else
 DECLARE_PER_CPU_PAGE_ALIGNED_USER_MAPPED(struct gdt_page, gdt_page);
+#endif
 
 static inline struct desc_struct *get_cpu_gdt_table(unsigned int cpu)
 {
--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -78,7 +78,9 @@ enum fixed_addresses {
 	VSYSCALL_LAST_PAGE,
 	VSYSCALL_FIRST_PAGE = VSYSCALL_LAST_PAGE
 			    + ((VSYSCALL_END-VSYSCALL_START) >> PAGE_SHIFT) - 1,
+#ifndef __GENKSYMS__
 	VVAR_PAGE,
+#endif
 	VSYSCALL_HPET,
 #endif
 	FIX_DBGP_BASE,
--- a/arch/x86/include/asm/hw_irq.h
+++ b/arch/x86/include/asm/hw_irq.h
@@ -166,7 +166,11 @@ extern asmlinkage void smp_invalidate_in
 extern void (*__initconst interrupt[NR_VECTORS-FIRST_EXTERNAL_VECTOR])(void);
 
 typedef int vector_irq_t[NR_VECTORS];
+#ifndef __GENKSYMS__
 DECLARE_PER_CPU_USER_MAPPED(vector_irq_t, vector_irq);
+#else
+DECLARE_PER_CPU(vector_irq_t, vector_irq);
+#endif
 extern void setup_vector_irq(int cpu);
 
 #ifdef CONFIG_X86_IO_APIC
--- a/arch/x86/include/asm/processor.h
+++ b/arch/x86/include/asm/processor.h
@@ -266,7 +266,11 @@ struct tss_struct {
 
 } ____cacheline_aligned;
 
+#ifndef __GENKSYMS__
 DECLARE_PER_CPU_SHARED_ALIGNED_USER_MAPPED(struct tss_struct, init_tss);
+#else
+DECLARE_PER_CPU_SHARED_ALIGNED(struct tss_struct, init_tss);
+#endif
 
 /*
  * Save the original ist values for checking stack pointers during debugging
--- a/arch/x86/include/asm/tlbflush.h
+++ b/arch/x86/include/asm/tlbflush.h
@@ -6,7 +6,9 @@
 
 #include <asm/processor.h>
 #include <asm/system.h>
+#ifndef __GENKSYMS__
 #include <asm/smp.h>
+#endif
 
 static inline void __invpcid(unsigned long pcid, unsigned long addr,
 			     unsigned long type)
--- a/arch/x86/kernel/cpu/common.c
+++ b/arch/x86/kernel/cpu/common.c
@@ -84,7 +84,11 @@ static const struct cpu_dev __cpuinitcon
 
 static const struct cpu_dev *this_cpu __cpuinitdata = &default_cpu;
 
+#ifndef __GENKSYMS__
 DEFINE_PER_CPU_PAGE_ALIGNED_USER_MAPPED(struct gdt_page, gdt_page) = { .gdt = {
+#else
+DEFINE_PER_CPU_PAGE_ALIGNED(struct gdt_page, gdt_page) = { .gdt = {
+#endif
 #ifdef CONFIG_X86_64
 	/*
 	 * We need valid kernel segments for data and code in long mode too
--- a/arch/x86/kernel/init_task.c
+++ b/arch/x86/kernel/init_task.c
@@ -38,5 +38,9 @@ EXPORT_SYMBOL(init_task);
  * section. Since TSS's are completely CPU-local, we want them
  * on exact cacheline boundaries, to eliminate cacheline ping-pong.
  */
+#if defined(CONFIG_GENKSYMS)
+DEFINE_PER_CPU_SHARED_ALIGNED(struct tss_struct, init_tss) = INIT_TSS;
+#else
 DEFINE_PER_CPU_SHARED_ALIGNED_USER_MAPPED(struct tss_struct, init_tss) = INIT_TSS;
+#endif
 
--- a/include/linux/mmu_context.h
+++ b/include/linux/mmu_context.h
@@ -1,7 +1,9 @@
 #ifndef _LINUX_MMU_CONTEXT_H
 #define _LINUX_MMU_CONTEXT_H
 
+#ifndef __GENKSYMS__
 #include <asm/mmu_context.h>
+#endif
 
 struct mm_struct;
 
--- a/kernel/sched.c
+++ b/kernel/sched.c
@@ -32,7 +32,11 @@
 #include <linux/init.h>
 #include <linux/uaccess.h>
 #include <linux/highmem.h>
+#ifdef __GENKSYMS__
+#include <asm/mmu_context.h>
+#else
 #include <linux/mmu_context.h>
+#endif
 #include <linux/interrupt.h>
 #include <linux/capability.h>
 #include <linux/completion.h>

