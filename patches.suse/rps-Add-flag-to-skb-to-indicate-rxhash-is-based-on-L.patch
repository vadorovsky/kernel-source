From: Tom Herbert <therbert@google.com>
Date: Sun, 14 Aug 2011 19:45:55 +0000
Patch-mainline: v3.2-rc1
Subject: rps: Add flag to skb to indicate rxhash is based on L4 tuple
Git-commit: bdeab991918663aed38757904219e8398214334c
References: fate#317533

The l4_rxhash flag was added to the skb structure to indicate
that the rxhash value was computed over the 4 tuple for the
packet which includes the port information in the encapsulated
transport packet.  This is used by the stack to preserve the
rxhash value in __skb_rx_tunnel.

Signed-off-by: Tom Herbert <therbert@google.com>
Signed-off-by: David S. Miller <davem@davemloft.net>
Acked-by: <ohering@suse.de>
---
 include/linux/skbuff.h |    3 +++
 include/net/dst.h      |    9 ++++++++-
 include/net/sock.h     |   15 ++++++++++++---
 net/core/dev.c         |   10 +++++++---
 net/core/skbuff.c      |    1 +
 net/ipv4/tcp_ipv4.c    |    6 +++---
 net/ipv4/udp.c         |    4 ++--
 net/ipv6/tcp_ipv6.c    |    6 +++---
 net/ipv6/udp.c         |    2 +-
 9 files changed, 40 insertions(+), 16 deletions(-)

--- a/include/linux/skbuff.h
+++ b/include/linux/skbuff.h
@@ -438,6 +438,9 @@ struct sk_buff {
 	__u8			pfmemalloc:1;
 	__u8			ooo_okay:1;
 	__u8			no_fcs:1;
+#ifndef __GENKSYMS__
+	__u8			l4_rxhash:1;
+#endif
 	/* Encapsulation protocol and NIC drivers should use
 	 * this flag to indicate to each other if the skb contains
 	 * encapsulated packet or not and maybe use the inner packet
--- a/include/net/dst.h
+++ b/include/net/dst.h
@@ -342,7 +342,14 @@ static inline void skb_dst_force(struct
 static inline void __skb_tunnel_rx(struct sk_buff *skb, struct net_device *dev)
 {
 	skb->dev = dev;
-	skb->rxhash = 0;
+
+	/*
+	 * Clear rxhash so that we can recalulate the hash for the
+	 * encapsulated packet, unless we have already determine the hash
+	 * over the L4 4-tuple.
+	 */
+	if (!skb->l4_rxhash)
+		skb->rxhash = 0;
 	skb_set_queue_mapping(skb, 0);
 	skb_dst_drop(skb);
 	nf_reset(skb);
--- a/include/net/sock.h
+++ b/include/net/sock.h
@@ -718,16 +718,25 @@ static inline void sock_rps_reset_flow(c
 #endif
 }
 
-static inline void sock_rps_save_rxhash(struct sock *sk, u32 rxhash)
+static inline void sock_rps_save_rxhash(struct sock *sk,
+					const struct sk_buff *skb)
 {
 #ifdef CONFIG_RPS
-	if (unlikely(sk->sk_rxhash != rxhash)) {
+	if (unlikely(sk->sk_rxhash != skb->rxhash)) {
 		sock_rps_reset_flow(sk);
-		sk->sk_rxhash = rxhash;
+		sk->sk_rxhash = skb->rxhash;
 	}
 #endif
 }
 
+static inline void sock_rps_reset_rxhash(struct sock *sk)
+{
+#ifdef CONFIG_RPS
+	sock_rps_reset_flow(sk);
+	sk->sk_rxhash = 0;
+#endif
+}
+
 #define sk_wait_event(__sk, __timeo, __condition)			\
 	({	int __rc;						\
 		release_sock(__sk);					\
--- a/net/core/dev.c
+++ b/net/core/dev.c
@@ -2716,8 +2716,9 @@ static inline void ____napi_schedule(str
 
 /*
  * __skb_get_rxhash: calculate a flow hash based on src/dst addresses
- * and src/dst port numbers. Returns a non-zero hash number on success
- * and 0 on failure.
+ * and src/dst port numbers.  Sets rxhash in skb to non-zero hash value
+ * on success, zero indicates no valid hash.  Also, sets l4_rxhash in skb
+ * if hash is a canonical 4-tuple hash over transport ports.
  */
 __u32 __skb_get_rxhash(struct sk_buff *skb)
 {
@@ -2765,8 +2766,10 @@ __u32 __skb_get_rxhash(struct sk_buff *s
 	poff = proto_ports_offset(ip_proto);
 	if (poff >= 0) {
 		nhoff += ihl * 4 + poff;
-		if (pskb_may_pull(skb, nhoff + 4))
+		if (pskb_may_pull(skb, nhoff + 4)) {
 			ports.v32 = * (__force u32 *) (skb->data + nhoff);
+			skb->l4_rxhash = 1;
+		}
 	}
 
 	/* get a consistent hash (same value on both flow directions) */
@@ -2782,6 +2785,7 @@ __u32 __skb_get_rxhash(struct sk_buff *s
 		hash = 1;
 
 done:
+	skb->rxhash = hash;
 	return hash;
 }
 EXPORT_SYMBOL(__skb_get_rxhash);
--- a/net/core/skbuff.c
+++ b/net/core/skbuff.c
@@ -582,6 +582,7 @@ static void __copy_skb_header(struct sk_
 	skb_dst_copy(new, old);
 	new->rxhash		= old->rxhash;
 	new->no_fcs		= old->no_fcs;
+	new->l4_rxhash		= old->l4_rxhash;
 	new->encapsulation	= old->encapsulation;
 #ifdef CONFIG_XFRM
 	new->sp			= secpath_get(old->sp);
--- a/net/ipv4/tcp_ipv4.c
+++ b/net/ipv4/tcp_ipv4.c
@@ -1588,7 +1588,7 @@ int tcp_v4_do_rcv(struct sock *sk, struc
 #endif
 
 	if (sk->sk_state == TCP_ESTABLISHED) { /* Fast path */
-		sock_rps_save_rxhash(sk, skb->rxhash);
+		sock_rps_save_rxhash(sk, skb);
 		if (tcp_rcv_established(sk, skb, tcp_hdr(skb), skb->len)) {
 			rsk = sk;
 			goto reset;
@@ -1605,7 +1605,7 @@ int tcp_v4_do_rcv(struct sock *sk, struc
 			goto discard;
 
 		if (nsk != sk) {
-			sock_rps_save_rxhash(nsk, skb->rxhash);
+			sock_rps_save_rxhash(nsk, skb);
 			if (tcp_child_process(sk, nsk, skb)) {
 				rsk = nsk;
 				goto reset;
@@ -1613,7 +1613,7 @@ int tcp_v4_do_rcv(struct sock *sk, struc
 			return 0;
 		}
 	} else
-		sock_rps_save_rxhash(sk, skb->rxhash);
+		sock_rps_save_rxhash(sk, skb);
 
 	if (tcp_rcv_state_process(sk, skb, tcp_hdr(skb), skb->len)) {
 		rsk = sk;
--- a/net/ipv4/udp.c
+++ b/net/ipv4/udp.c
@@ -1263,7 +1263,7 @@ int udp_disconnect(struct sock *sk, int
 	sk->sk_state = TCP_CLOSE;
 	inet->inet_daddr = 0;
 	inet->inet_dport = 0;
-	sock_rps_save_rxhash(sk, 0);
+	sock_rps_reset_rxhash(sk);
 	sk->sk_bound_dev_if = 0;
 	if (!(sk->sk_userlocks & SOCK_BINDADDR_LOCK))
 		inet_reset_saddr(sk);
@@ -1351,7 +1351,7 @@ static int __udp_queue_rcv_skb(struct so
 	int rc;
 
 	if (inet_sk(sk)->inet_daddr)
-		sock_rps_save_rxhash(sk, skb->rxhash);
+		sock_rps_save_rxhash(sk, skb);
 
 	rc = ip_queue_rcv_skb(sk, skb);
 	if (rc < 0) {
--- a/net/ipv6/tcp_ipv6.c
+++ b/net/ipv6/tcp_ipv6.c
@@ -1637,7 +1637,7 @@ static int tcp_v6_do_rcv(struct sock *sk
 		opt_skb = skb_clone(skb, sk_gfp_atomic(sk, GFP_ATOMIC));
 
 	if (sk->sk_state == TCP_ESTABLISHED) { /* Fast path */
-		sock_rps_save_rxhash(sk, skb->rxhash);
+		sock_rps_save_rxhash(sk, skb);
 		if (tcp_rcv_established(sk, skb, tcp_hdr(skb), skb->len))
 			goto reset;
 		if (opt_skb)
@@ -1659,7 +1659,7 @@ static int tcp_v6_do_rcv(struct sock *sk
 		 * the new socket..
 		 */
 		if(nsk != sk) {
-			sock_rps_save_rxhash(nsk, skb->rxhash);
+			sock_rps_save_rxhash(nsk, skb);
 			if (tcp_child_process(sk, nsk, skb))
 				goto reset;
 			if (opt_skb)
@@ -1667,7 +1667,7 @@ static int tcp_v6_do_rcv(struct sock *sk
 			return 0;
 		}
 	} else
-		sock_rps_save_rxhash(sk, skb->rxhash);
+		sock_rps_save_rxhash(sk, skb);
 
 	if (tcp_rcv_state_process(sk, skb, tcp_hdr(skb), skb->len))
 		goto reset;
--- a/net/ipv6/udp.c
+++ b/net/ipv6/udp.c
@@ -508,7 +508,7 @@ int udpv6_queue_rcv_skb(struct sock * sk
 	int is_udplite = IS_UDPLITE(sk);
 
 	if (!ipv6_addr_any(&inet6_sk(sk)->daddr))
-		sock_rps_save_rxhash(sk, skb->rxhash);
+		sock_rps_save_rxhash(sk, skb);
 
 	if (!xfrm6_policy_check(sk, XFRM_POLICY_IN, skb))
 		goto drop;
