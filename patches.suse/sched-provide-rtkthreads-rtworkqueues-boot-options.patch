Subject: sched: Provide realtime priority kthread and workqueue boot options
From: Mike Galbraith <mgalbraith@suse.de>
Date: Tue Oct  8 06:27:03 CEST 2013
Patch-mainline: never, SUSE specific
References: bnc#836718

Nasty hack to allow users to abuse realtime without starving the kernel,
and reaping the consequences thereof.

Boot box nortsched rtkthreads=N and optionally rtworkqueues=N+1, and the
user can slam a box into the saturation wall without starving the kernel
IFF he restricts userspace to priority < N.

Signed-off-by: Mike Galbraith <mgalbraith@suse.de>
---
 Documentation/kernel-parameters.txt |    4 +++
 kernel/kthread.c                    |   37 ++++++++++++++++++++++++++++++-
 kernel/workqueue.c                  |   42 +++++++++++++++++++++++++++++++++++-
 3 files changed, 80 insertions(+), 3 deletions(-)

--- a/Documentation/kernel-parameters.txt
+++ b/Documentation/kernel-parameters.txt
@@ -3430,6 +3430,10 @@ bytes respectively. Such letter suffixes
 			Memory area to be used by remote processor image,
 			managed by CMA.
 
+	rtkthreads=	[KNL] kernel threads run as SCHED_FIFO at the provided priority (1..99).
+
+	rtworkqueues=	[KNL] kworker threads run as SCHED_FIFO at the provided priority (1..99).
+
 	rw		[KNL] Mount root device read-write on boot
 
 	S		[KNL] Run init in single mode
--- a/kernel/kthread.c
+++ b/kernel/kthread.c
@@ -244,6 +244,24 @@ static void create_kthread(struct kthrea
 	}
 }
 
+static struct sched_param fifo_param, normal_param;
+
+static inline void kthread_set_sched_params(struct task_struct *kthread)
+{
+	if (!fifo_param.sched_priority) {
+		sched_setscheduler_nocheck(kthread, SCHED_NORMAL, &normal_param);
+		return;
+	}
+	sched_setscheduler_nocheck(kthread, SCHED_FIFO, &fifo_param);
+}
+
+static inline void kthread_clr_sched_params(struct task_struct *kthread)
+{
+	if (!fifo_param.sched_priority || kthread->policy != SCHED_FIFO)
+		return;
+	sched_setscheduler_nocheck(kthread, SCHED_NORMAL, &normal_param);
+}
+
 /**
  * kthread_create_on_node - create a kthread.
  * @threadfn: the function to run until signal_pending(current).
@@ -310,7 +328,6 @@ struct task_struct *kthread_create_on_no
 	}
 	task = create->result;
 	if (!IS_ERR(task)) {
-		static const struct sched_param param = { .sched_priority = 0 };
 		va_list args;
 
 		va_start(args, namefmt);
@@ -320,7 +337,7 @@ struct task_struct *kthread_create_on_no
 		 * root may have changed our (kthreadd's) priority or CPU mask.
 		 * The kernel thread should not inherit these properties.
 		 */
-		sched_setscheduler_nocheck(task, SCHED_NORMAL, &param);
+		kthread_set_sched_params(create->result);
 		set_cpus_allowed_ptr(task, cpu_all_mask);
 	}
 	kfree(create);
@@ -488,6 +505,7 @@ int kthread_stop(struct task_struct *k)
 	if (kthread) {
 		set_bit(KTHREAD_SHOULD_STOP, &kthread->flags);
 		__kthread_unpark(k, kthread);
+		kthread_clr_sched_params(k);
 		wake_up_process(k);
 		wait_for_completion(&kthread->exited);
 	}
@@ -508,6 +526,7 @@ int kthreadd(void *unused)
 	ignore_signals(tsk);
 	set_cpus_allowed_ptr(tsk, cpu_all_mask);
 	set_mems_allowed(node_states[N_MEMORY]);
+	kthread_set_sched_params(current);
 
 	current->flags |= PF_NOFREEZE;
 
@@ -709,3 +728,17 @@ void flush_kthread_worker(struct kthread
 	wait_for_completion(&fwork.done);
 }
 EXPORT_SYMBOL_GPL(flush_kthread_worker);
+
+static int __init setup_rtkthreads(char *str)
+{
+	int prio;
+
+	if (kstrtoint(str, 0, &prio) || prio < 1 || prio > 99) {
+		prio = 0;
+		pr_warn("Unable to set kthread default priority\n");
+	}
+	fifo_param.sched_priority = prio;
+
+        return 1;
+}
+__setup("rtkthreads=", setup_rtkthreads);
--- a/kernel/workqueue.c
+++ b/kernel/workqueue.c
@@ -1612,6 +1612,27 @@ static struct worker *alloc_worker(int n
 	return worker;
 }
 
+static struct sched_param fifo_param, normal_param;
+
+static inline void kworker_set_sched_params(struct task_struct *worker)
+{
+	int prio = fifo_param.sched_priority;
+	if (!prio || in_interrupt())
+		return;
+	if (worker->policy == SCHED_FIFO && worker->rt_priority == prio)
+		return;
+	sched_setscheduler_nocheck(worker, SCHED_FIFO, &fifo_param);
+}
+
+static inline void kworker_clr_sched_params(struct task_struct *worker)
+{
+	if (!fifo_param.sched_priority || worker->policy != SCHED_FIFO)
+		return;
+	if (in_interrupt())
+		return;
+	sched_setscheduler_nocheck(worker, SCHED_NORMAL, &normal_param);
+}
+
 /**
  * worker_attach_to_pool() - attach a worker to a pool
  * @worker: worker to be attached
@@ -1715,6 +1736,7 @@ static struct worker *create_worker(stru
 
 	set_user_nice(worker->task, pool->attrs->nice);
 	kthread_bind_mask(worker->task, pool->attrs->cpumask);
+	kworker_set_sched_params(worker->task);
 
 	/* successful, attach the worker to the pool */
 	worker_attach_to_pool(worker, pool);
@@ -1762,6 +1784,7 @@ static void destroy_worker(struct worker
 
 	list_del_init(&worker->entry);
 	worker->flags |= WORKER_DIE;
+	kworker_clr_sched_params(worker->task);
 	wake_up_process(worker->task);
 }
 
@@ -3857,6 +3880,7 @@ struct workqueue_struct *__alloc_workque
 
 		wq->rescuer = rescuer;
 		kthread_bind_mask(rescuer->task, cpu_possible_mask);
+		kworker_set_sched_params(rescuer->task);
 		wake_up_process(rescuer->task);
 	}
 
@@ -3936,8 +3960,10 @@ void destroy_workqueue(struct workqueue_
 
 	workqueue_sysfs_unregister(wq);
 
-	if (wq->rescuer)
+	if (wq->rescuer) {
+		kworker_clr_sched_params(wq->rescuer->task);
 		kthread_stop(wq->rescuer->task);
+	}
 
 	if (!(wq->flags & WQ_UNBOUND)) {
 		/*
@@ -5293,3 +5319,17 @@ static int __init init_workqueues(void)
 	return 0;
 }
 early_initcall(init_workqueues);
+
+static int __init setup_rtworkqueues(char *str)
+{
+	int prio;
+
+	if (kstrtoint(str, 0, &prio) || prio < 1 || prio > 99) {
+		prio = 0;
+		pr_warn("Unable to set kworker default priority\n");
+	}
+	fifo_param.sched_priority = prio;
+
+        return 1;
+}
+__setup("rtworkqueues=", setup_rtworkqueues);
