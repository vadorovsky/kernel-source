From d6b94b7aafe161a4ea4bccff3aeecf701187b0d7 Mon Sep 17 00:00:00 2001
From: Ram Pai <linuxram@us.ibm.com>
Date: Fri, 12 Jan 2018 19:25:21 +0100
Subject: [PATCH] powerpc/rfi-flush: Move RFI flush fields out of the
 paca (unbreak kABI)

References: bsc#1068032, bsc#1075087
Patch-mainline: no, kabi

In order to avoid breaking kABI on distros that use it, we move the RFI
related fields out of the paca and into an auxillary structure.

We place the pointer to the auxillary structure in a hole that exists
prior to exgen.

Patch by Nick, reworked a bit by me.

Signed-off-by: Ram Pai <linuxram@us.ibm.com>
Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
Acked-by: Michal Suchanek <msuchanek@suse.de>
---
 arch/powerpc/include/asm/paca.h      | 35 +++++++++++++++++++++++++----------
 arch/powerpc/kernel/asm-offsets.c    | 10 ++++++----
 arch/powerpc/kernel/exceptions-64s.S |  2 ++
 arch/powerpc/kernel/paca.c           | 30 +++++++++++++++++++++++++++---
 arch/powerpc/kernel/setup_64.c       |  7 ++++---
 5 files changed, 64 insertions(+), 20 deletions(-)

diff --git a/arch/powerpc/include/asm/paca.h b/arch/powerpc/include/asm/paca.h
index c34da6ea39ed..c090806353f9 100644
--- a/arch/powerpc/include/asm/paca.h
+++ b/arch/powerpc/include/asm/paca.h
@@ -44,6 +44,23 @@ extern unsigned int debug_smp_processor_id(void); /* from linux/smp.h */
 struct task_struct;
 
 /*
+ * This is pointed to by paca->aux_ptr, for the purpose of extending the
+ * paca structure without kABI breakage.
+ */
+#ifdef CONFIG_PPC_STD_MMU_64
+struct paca_aux_struct {
+	/*
+	 * rfi fallback flush must be in its own cacheline to prevent
+	 * other paca data leaking into the L1d
+	 */
+	u64 exrfi[13] __aligned(0x80);
+	void *rfi_flush_fallback_area;
+	u64 l1d_flush_congruence;
+	u64 l1d_flush_sets;
+};
+#endif
+
+/*
  * Defines the layout of the paca.
  *
  * This structure is not directly accessed by firmware or the service
@@ -91,6 +108,14 @@ struct paca_struct {
 	u64 dscr_default;		/* per-CPU default DSCR */
 
 #ifdef CONFIG_PPC_STD_MMU_64
+#ifndef __GENKSYMS__
+	/*
+	 * Because of alignment of exgen there is a hole here, we use that hole
+	 * for the aux_ptr and so don't change the size of the paca or the
+	 * location of any members.
+	 */
+	struct paca_aux_struct *aux_ptr;
+#endif /* __GENKSYMS__ */
 	/*
 	 * Now, starting in cacheline 2, the exception save areas
 	 */
@@ -193,16 +218,6 @@ struct paca_struct {
 #endif
 	struct kvmppc_host_state kvm_hstate;
 #endif
-#ifdef CONFIG_PPC_BOOK3S_64
-	/*
-	 * rfi fallback flush must be in its own cacheline to prevent
-	 * other paca data leaking into the L1d
-	 */
-	u64 exrfi[13] __aligned(0x80);
-	void *rfi_flush_fallback_area;
-	u64 l1d_flush_congruence;
-	u64 l1d_flush_sets;
-#endif
 };
 
 extern void copy_mm_to_paca(struct mm_struct *mm);
diff --git a/arch/powerpc/kernel/asm-offsets.c b/arch/powerpc/kernel/asm-offsets.c
index 8660be14d99a..3269e39a978b 100644
--- a/arch/powerpc/kernel/asm-offsets.c
+++ b/arch/powerpc/kernel/asm-offsets.c
@@ -239,15 +239,17 @@ int main(void)
 	DEFINE(LPPACA_DTLIDX, offsetof(struct lppaca, dtl_idx));
 	DEFINE(LPPACA_YIELDCOUNT, offsetof(struct lppaca, yield_count));
 	DEFINE(PACA_DTL_RIDX, offsetof(struct paca_struct, dtl_ridx));
+	/* paca_aux_struct stuff: */
+	OFFSET(PACA_AUX_PTR, paca_struct, aux_ptr);
+	OFFSET(PACA_RFI_FLUSH_FALLBACK_AREA, paca_aux_struct, rfi_flush_fallback_area);
+	OFFSET(PACA_EXRFI, paca_aux_struct, exrfi);
+	OFFSET(PACA_L1D_FLUSH_CONGRUENCE, paca_aux_struct, l1d_flush_congruence);
+	OFFSET(PACA_L1D_FLUSH_SETS, paca_aux_struct, l1d_flush_sets);
 #endif /* CONFIG_PPC_STD_MMU_64 */
 	DEFINE(PACAEMERGSP, offsetof(struct paca_struct, emergency_sp));
 #ifdef CONFIG_PPC_BOOK3S_64
 	DEFINE(PACAMCEMERGSP, offsetof(struct paca_struct, mc_emergency_sp));
 	DEFINE(PACA_IN_MCE, offsetof(struct paca_struct, in_mce));
-	DEFINE(PACA_RFI_FLUSH_FALLBACK_AREA, offsetof(struct paca_struct, rfi_flush_fallback_area));
-	DEFINE(PACA_EXRFI, offsetof(struct paca_struct, exrfi));
-	DEFINE(PACA_L1D_FLUSH_CONGRUENCE, offsetof(struct paca_struct, l1d_flush_congruence));
-	DEFINE(PACA_L1D_FLUSH_SETS, offsetof(struct paca_struct, l1d_flush_sets));
 #endif
 	DEFINE(PACAHWCPUID, offsetof(struct paca_struct, hw_cpu_id));
 	DEFINE(PACAKEXECSTATE, offsetof(struct paca_struct, kexec_state));
diff --git a/arch/powerpc/kernel/exceptions-64s.S b/arch/powerpc/kernel/exceptions-64s.S
index cb8b319e97c0..14e0d5e4ccc3 100644
--- a/arch/powerpc/kernel/exceptions-64s.S
+++ b/arch/powerpc/kernel/exceptions-64s.S
@@ -1568,6 +1568,7 @@ power4_fixup_nap:
 rfi_flush_fallback:
 	SET_SCRATCH0(r13);
 	GET_PACA(r13);
+	ld	r13,PACA_AUX_PTR(r13) /* r13 now = paca_aux pointer */
 	std	r9,PACA_EXRFI+EX_R9(r13)
 	std	r10,PACA_EXRFI+EX_R10(r13)
 	std	r11,PACA_EXRFI+EX_R11(r13)
@@ -1611,6 +1612,7 @@ rfi_flush_fallback:
 hrfi_flush_fallback:
 	SET_SCRATCH0(r13);
 	GET_PACA(r13);
+	ld	r13,PACA_AUX_PTR(r13) /* r13 now = paca_aux pointer */
 	std	r9,PACA_EXRFI+EX_R9(r13)
 	std	r10,PACA_EXRFI+EX_R10(r13)
 	std	r11,PACA_EXRFI+EX_R11(r13)
diff --git a/arch/powerpc/kernel/paca.c b/arch/powerpc/kernel/paca.c
index 3085a2ff2e6d..8be590359967 100644
--- a/arch/powerpc/kernel/paca.c
+++ b/arch/powerpc/kernel/paca.c
@@ -147,6 +147,15 @@ static void __init allocate_slb_shadows(int nr_cpus, int limit) { }
 struct paca_struct *paca;
 EXPORT_SYMBOL(paca);
 
+#ifdef CONFIG_PPC_STD_MMU_64
+/*
+ * Auxiliary structure that can be used to basically add fields to the
+ * paca without changing its size (for kABI purposes). Upstream code should
+ * have these fields directly in the paca.
+ */
+static struct paca_aux_struct * __initdata paca_aux;
+#endif /* CONFIG_PPC_STD_MMU_64 */
+
 void __init initialise_paca(struct paca_struct *new_paca, int cpu)
 {
        /* The TOC register (GPR2) points 32kB into the TOC, so that 64kB
@@ -171,6 +180,7 @@ void __init initialise_paca(struct paca_struct *new_paca, int cpu)
 	new_paca->data_offset = 0xfeeeeeeeeeeeeeeeULL;
 #ifdef CONFIG_PPC_STD_MMU_64
 	new_paca->slb_shadow_ptr = init_slb_shadow(cpu);
+	new_paca->aux_ptr = &paca_aux[cpu];
 #endif /* CONFIG_PPC_STD_MMU_64 */
 
 #ifdef CONFIG_PPC_BOOK3E
@@ -201,6 +211,7 @@ void setup_paca(struct paca_struct *new_paca)
 }
 
 static int __initdata paca_size;
+static int __initdata paca_aux_size;
 
 void __init allocate_pacas(void)
 {
@@ -223,8 +234,15 @@ void __init allocate_pacas(void)
 	paca = __va(memblock_alloc_base(paca_size, PAGE_SIZE, limit));
 	memset(paca, 0, paca_size);
 
-	printk(KERN_DEBUG "Allocated %u bytes for %d pacas at %p\n",
-		paca_size, nr_cpu_ids, paca);
+#ifdef CONFIG_PPC_STD_MMU_64
+	paca_aux_size = PAGE_ALIGN(sizeof(struct paca_aux_struct) * nr_cpu_ids);
+
+	paca_aux = __va(memblock_alloc_base(paca_aux_size, PAGE_SIZE, limit));
+	memset(paca_aux, 0, paca_aux_size);
+#endif /* CONFIG_PPC_STD_MMU_64 */
+
+	printk(KERN_DEBUG "Allocated %u bytes for %u pacas at %p\n",
+		paca_size + paca_aux_size, nr_cpu_ids, paca);
 
 	allocate_lppacas(nr_cpu_ids, limit);
 
@@ -238,18 +256,24 @@ void __init allocate_pacas(void)
 void __init free_unused_pacas(void)
 {
 	int new_size;
+	int new_aux_size;
 
 	new_size = PAGE_ALIGN(sizeof(struct paca_struct) * nr_cpu_ids);
+	new_aux_size = PAGE_ALIGN(sizeof(struct paca_aux_struct) * nr_cpu_ids);
 
 	if (new_size >= paca_size)
 		return;
 
 	memblock_free(__pa(paca) + new_size, paca_size - new_size);
+#ifdef CONFIG_PPC_STD_MMU_64
+	memblock_free(__pa(paca_aux) + new_aux_size, paca_aux_size - new_aux_size);
+#endif /* CONFIG_PPC_STD_MMU_64 */
 
 	printk(KERN_DEBUG "Freed %u bytes for unused pacas\n",
-		paca_size - new_size);
+		paca_size - new_size + paca_aux_size - new_aux_size);
 
 	paca_size = new_size;
+	paca_aux_size = new_aux_size;
 
 	free_lppacas();
 }
diff --git a/arch/powerpc/kernel/setup_64.c b/arch/powerpc/kernel/setup_64.c
index 11aa62a7d1e3..9dac11057744 100644
--- a/arch/powerpc/kernel/setup_64.c
+++ b/arch/powerpc/kernel/setup_64.c
@@ -910,6 +910,7 @@ static void init_fallback_flush(void)
 	memset(l1d_flush_fallback_area, 0, l1d_size * 2);
 
 	for_each_possible_cpu(cpu) {
+		struct paca_aux_struct *paca_aux = paca[cpu].aux_ptr;
 		/*
 		 * The fallback flush is currently coded for 8-way
 		 * associativity. Different associativity is possible, but it
@@ -920,9 +921,9 @@ static void init_fallback_flush(void)
 		 */
 		u64 c = l1d_size / 8;
 
-		paca[cpu].rfi_flush_fallback_area = l1d_flush_fallback_area;
-		paca[cpu].l1d_flush_congruence = c;
-		paca[cpu].l1d_flush_sets = c / 128;
+		paca_aux->rfi_flush_fallback_area = l1d_flush_fallback_area;
+		paca_aux->l1d_flush_congruence = c;
+		paca_aux->l1d_flush_sets = c / 128;
 	}
 }
 
-- 
2.13.6

